{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import hashlib\n",
    "import re\n",
    "from attr import dataclass\n",
    "import pandas as pd\n",
    "from logai.algorithms.algo_interfaces import ParsingAlgo\n",
    "\n",
    "\n",
    "#IPLoM\n",
    "\n",
    "@dataclass\n",
    "class IPLoMParams:\n",
    "    \"\"\"Para class\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        maxEventLen : the length of the longest log/event, which is used in step 1 to split logs into partitions\n",
    "            according to their length\n",
    "        path : the path of the input file\n",
    "        support : the support threshold to create a new partition, partitions which contains less than\n",
    "            support logs will not go through step 2\n",
    "        PST : Partition support ratio threshold\n",
    "        CT : Cluster goodness threshold used in DetermineP1P2 in step3. If the columns with unique term more\n",
    "            than CT, we skip step 3\n",
    "    \"\"\"\n",
    "    maxEventLen:int = 200\n",
    "    support:float = 0\n",
    "    PST:float = 0\n",
    "    CT:float = 0.35\n",
    "    lowerBound:float = 0.25\n",
    "    upperBound:float = 0.9\n",
    "    rex:list = []\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Partition:\n",
    "    \"\"\"Wrap around the logs and the step number\"\"\"\n",
    "    logLL:list = []\n",
    "    stepNo:int = 0\n",
    "    valid:bool = True\n",
    "    numOfLogs:int = 0\n",
    "    lenOfLogs:int = 0\n",
    "\n",
    "\n",
    "class Event:\n",
    "    def __init__(self, event_str):\n",
    "        self.eventStr = event_str\n",
    "        self.eventId = hashlib.md5(\" \".join(event_str).encode(\"utf-8\")).hexdigest()[0:8]\n",
    "        self.eventCount = 0\n",
    "\n",
    "\n",
    "class IPLoM(ParsingAlgo):\n",
    "    def __init__(\n",
    "            self,\n",
    "            params=IPLoMParams,\n",
    "            keep_params=True\n",
    "    ):\n",
    "        self.params = params\n",
    "        self.partitionsL = []\n",
    "        self.eventsL = []\n",
    "        self.output = []\n",
    "        self.keep_params = keep_params\n",
    "        # Initialize some partitions which contain logs with different length\n",
    "        for logLen in range(self.params.maxEventLen + 1):\n",
    "            self.partitionsL.append(Partition(stepNo=1, numOfLogs=0, lenOfLogs=logLen))\n",
    "        return\n",
    "\n",
    "    def step1(self, loglines):\n",
    "\n",
    "        lineCounts = 1\n",
    "        for idx, line in loglines.iteritems():\n",
    "            if not line.strip():\n",
    "                continue\n",
    "            if self.params.rex:\n",
    "                for currentRex in self.params.rex:\n",
    "                    line = re.sub(currentRex, \" \", line)\n",
    "\n",
    "            tokens = line.split(\" \")\n",
    "            if not tokens:\n",
    "                tokens = [\" \"]\n",
    "\n",
    "            tokens.append(str(lineCounts))\n",
    "            lineCounts += 1\n",
    "\n",
    "            self.partitionsL[len(tokens) - 1].logLL.append(tokens)\n",
    "            self.partitionsL[len(tokens) - 1].numOfLogs += 1\n",
    "\n",
    "        for partition in self.partitionsL:\n",
    "            if partition.numOfLogs <= 0:\n",
    "                partition.valid = False\n",
    "\n",
    "            elif self.params.PST !=0 and 1.0 * partition.numOfLogs / len(line) < self.params.PST:\n",
    "                for logL in partition.logLL:\n",
    "                    self.partitionsL[0].logLL.append(logL)\n",
    "                    self.partitionsL[0].numOfLogs +=1\n",
    "                partition.valid = False\n",
    "\n",
    "    def step2(self):\n",
    "\n",
    "        for partition in self.partitionsL:\n",
    "\n",
    "            if not partition.valid:\n",
    "                continue\n",
    "\n",
    "            if partition.numOfLogs <= self.params.support:\n",
    "                continue\n",
    "\n",
    "            # Avoid going through newly generated partitions\n",
    "            if partition.stepNo == 2:\n",
    "                break\n",
    "\n",
    "            # For each column, create a set to hold the unique tokens in that column.\n",
    "            # And finally, calculate the number of the unique tokens in each column\n",
    "            uniqueTokensCountLS = []\n",
    "            for columnIdx in range(partition.lenOfLogs):\n",
    "                uniqueTokensCountLS.append(set())\n",
    "\n",
    "            for logL in partition.logLL:\n",
    "                for columnIdx in range(partition.lenOfLogs):\n",
    "                    uniqueTokensCountLS[columnIdx].add(logL[columnIdx])\n",
    "\n",
    "            # Find the column with minimum unique tokens\n",
    "            minColumnIdx = 0\n",
    "            minColumnCount = len(uniqueTokensCountLS[0])\n",
    "\n",
    "            for columnIdx in range(partition.lenOfLogs):\n",
    "                if minColumnCount > len(uniqueTokensCountLS[columnIdx]):\n",
    "                    minColumnCount = len(uniqueTokensCountLS[columnIdx])\n",
    "                    minColumnIdx = columnIdx\n",
    "\n",
    "            # If there is one column with one unique term, do not split this partition\n",
    "            if minColumnCount == 1:\n",
    "                continue\n",
    "\n",
    "            # From split-token to log list\n",
    "            logDLL = {}\n",
    "            for logL in partition.logLL:\n",
    "                if logL[minColumnIdx] not in logDLL:\n",
    "                    logDLL[logL[minColumnIdx]] = []\n",
    "                logDLL[logL[minColumnIdx]].append(logL)\n",
    "\n",
    "            for key in logDLL:\n",
    "                if (\n",
    "                    self.params.PST != 0\n",
    "                    and 1.0 * len(logDLL[key]) / partition.numOfLogs < self.params.PST\n",
    "                ):\n",
    "                    self.partitionsL[0].logLL += logDLL[key]\n",
    "                    self.partitionsL[0].numOfLogs += len(logDLL[key])\n",
    "                else:\n",
    "                    newPartition = Partition(\n",
    "                        stepNo=2,\n",
    "                        numOfLogs=len(logDLL[key]),\n",
    "                        lenOfLogs=partition.lenOfLogs,\n",
    "                    )\n",
    "                    newPartition.logLL = logDLL[key]\n",
    "                    self.partitionsL.append(newPartition)\n",
    "\n",
    "            partition.valid = False\n",
    "        for partition in self.partitionsL:\n",
    "\n",
    "            if not partition.valid:\n",
    "                continue\n",
    "\n",
    "            if partition.numOfLogs <= self.params.support:\n",
    "                continue\n",
    "\n",
    "            # Avoid going through newly generated partitions\n",
    "            if partition.stepNo == 2:\n",
    "                break\n",
    "\n",
    "            # For each column, create a set to hold the unique tokens in that column.\n",
    "            # And finally, calculate the number of the unique tokens in each column\n",
    "            uniqueTokensCountLS = []\n",
    "            for columnIdx in range(partition.lenOfLogs):\n",
    "                uniqueTokensCountLS.append(set())\n",
    "\n",
    "            for logL in partition.logLL:\n",
    "                for columnIdx in range(partition.lenOfLogs):\n",
    "                    uniqueTokensCountLS[columnIdx].add(logL[columnIdx])\n",
    "\n",
    "            # Find the column with minimum unique tokens\n",
    "            minColumnIdx = 0\n",
    "            minColumnCount = len(uniqueTokensCountLS[0])\n",
    "\n",
    "            for columnIdx in range(partition.lenOfLogs):\n",
    "                if minColumnCount > len(uniqueTokensCountLS[columnIdx]):\n",
    "                    minColumnCount = len(uniqueTokensCountLS[columnIdx])\n",
    "                    minColumnIdx = columnIdx\n",
    "\n",
    "            # If there is one column with one unique term, do not split this partition\n",
    "            if minColumnCount == 1:\n",
    "                continue\n",
    "\n",
    "            # From split-token to log list\n",
    "            logDLL = {}\n",
    "            for logL in partition.logLL:\n",
    "                if logL[minColumnIdx] not in logDLL:\n",
    "                    logDLL[logL[minColumnIdx]] = []\n",
    "                logDLL[logL[minColumnIdx]].append(logL)\n",
    "\n",
    "            for key in logDLL:\n",
    "                if (\n",
    "                    self.params.PST != 0\n",
    "                    and 1.0 * len(logDLL[key]) / partition.numOfLogs < self.params.PST\n",
    "                ):\n",
    "                    self.partitionsL[0].logLL += logDLL[key]\n",
    "                    self.partitionsL[0].numOfLogs += len(logDLL[key])\n",
    "                else:\n",
    "                    newPartition = Partition(\n",
    "                        stepNo=2,\n",
    "                        numOfLogs=len(logDLL[key]),\n",
    "                        lenOfLogs=partition.lenOfLogs,\n",
    "                    )\n",
    "                    newPartition.logLL = logDLL[key]\n",
    "                    self.partitionsL.append(newPartition)\n",
    "\n",
    "            partition.valid = False\n",
    "\n",
    "    def step3(self):\n",
    "\n",
    "        for partition in self.partitionsL:\n",
    "\n",
    "            if not partition.valid:\n",
    "                continue\n",
    "\n",
    "            if partition.stepNo == 3:\n",
    "                break\n",
    "\n",
    "            # Find two columns that my cause split in this step\n",
    "            p1, p2 = self.DetermineP1P2(partition)\n",
    "\n",
    "            if p1 == -1 or p2 == -1:\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "\n",
    "                p1Set = set()\n",
    "                p2Set = set()\n",
    "                mapRelation1DS = {}\n",
    "                mapRelation2DS = {}\n",
    "\n",
    "                # Construct token sets for p1 and p2, dictionary to record the mapping relations between p1 and p2\n",
    "                for logL in partition.logLL:\n",
    "                    p1Set.add(logL[p1])\n",
    "                    p2Set.add(logL[p2])\n",
    "\n",
    "                    if logL[p1] == logL[p2]:\n",
    "                        print(\"Warning: p1 may be equal to p2\")\n",
    "\n",
    "                    if logL[p1] not in mapRelation1DS:\n",
    "                        mapRelation1DS[logL[p1]] = set()\n",
    "                    mapRelation1DS[logL[p1]].add(logL[p2])\n",
    "\n",
    "                    if logL[p2] not in mapRelation2DS:\n",
    "                        mapRelation2DS[logL[p2]] = set()\n",
    "                    mapRelation2DS[logL[p2]].add(logL[p1])\n",
    "\n",
    "                # Construct sets to record the tokens in 1-1, 1-M, M-1 relationships, the left-tokens in p1Set & p2Set\n",
    "                # are in M-M relationships\n",
    "                oneToOneS = set()\n",
    "                oneToMP1D = {}\n",
    "                oneToMP2D = {}\n",
    "\n",
    "                # select 1-1 and 1-M relationships\n",
    "                for p1Token in p1Set:\n",
    "                    if len(mapRelation1DS[p1Token]) == 1:\n",
    "                        if len(mapRelation2DS[list(mapRelation1DS[p1Token])[0]]) == 1:\n",
    "                            oneToOneS.add(p1Token)\n",
    "\n",
    "                    else:\n",
    "                        isOneToM = True\n",
    "\n",
    "                        for p2Token in mapRelation1DS[p1Token]:\n",
    "                            if len(mapRelation2DS[p2Token]) != 1:\n",
    "                                isOneToM = False\n",
    "                                break\n",
    "                        if isOneToM:\n",
    "                            oneToMP1D[p1Token] = 0\n",
    "\n",
    "                # delete the tokens which are picked to 1-1 and 1-M relationships from p1Set, so that the left are M-M\n",
    "                for deleteToken in oneToOneS:\n",
    "                    p1Set.remove(deleteToken)\n",
    "                    p2Set.remove(list(mapRelation1DS[deleteToken])[0])\n",
    "\n",
    "                for deleteToken in oneToMP1D:\n",
    "                    for deleteTokenP2 in mapRelation1DS[deleteToken]:\n",
    "                        p2Set.remove(deleteTokenP2)\n",
    "                    p1Set.remove(deleteToken)\n",
    "\n",
    "                # select M-1 relationships\n",
    "                for p2Token in p2Set:\n",
    "                    if len(mapRelation2DS[p2Token]) != 1:\n",
    "                        isOneToM = True\n",
    "                        for p1Token in mapRelation2DS[p2Token]:\n",
    "                            if len(mapRelation1DS[p1Token]) != 1:\n",
    "                                isOneToM = False\n",
    "                                break\n",
    "                        if isOneToM:\n",
    "                            oneToMP2D[p2Token] = 0\n",
    "\n",
    "                # delete the tokens which are picked to M-1 relationships from p2Set, so that the left are M-M\n",
    "                for deleteToken in oneToMP2D:\n",
    "                    p2Set.remove(deleteToken)\n",
    "                    for deleteTokenP1 in mapRelation2DS[deleteToken]:\n",
    "                        p1Set.remove(deleteTokenP1)\n",
    "\n",
    "                # calculate the #Lines_that_match_S\n",
    "                for logL in partition.logLL:\n",
    "                    if logL[p1] in oneToMP1D:\n",
    "                        oneToMP1D[logL[p1]] += 1\n",
    "\n",
    "                    if logL[p2] in oneToMP2D:\n",
    "                        oneToMP2D[logL[p2]] += 1\n",
    "\n",
    "            except KeyError as er:\n",
    "                print(er)\n",
    "                print(\"error: \" + str(p1) + \"\\t\" + str(p2))\n",
    "\n",
    "            newPartitionsD = {}\n",
    "            if partition.stepNo == 2:\n",
    "                newPartitionsD[\"dumpKeyforMMrelationInStep2__\"] = Partition(\n",
    "                    stepNo=3, numOfLogs=0, lenOfLogs=partition.lenOfLogs\n",
    "                )\n",
    "            # Split partition\n",
    "            for logL in partition.logLL:\n",
    "                # If is 1-1\n",
    "                if logL[p1] in oneToOneS:\n",
    "                    if logL[p1] not in newPartitionsD:\n",
    "                        newPartitionsD[logL[p1]] = Partition(\n",
    "                            stepNo=3, numOfLogs=0, lenOfLogs=partition.lenOfLogs\n",
    "                        )\n",
    "                    newPartitionsD[logL[p1]].logLL.append(logL)\n",
    "                    newPartitionsD[logL[p1]].numOfLogs += 1\n",
    "\n",
    "                # This part can be improved. The split_rank can be calculated once.\n",
    "                # If is 1-M\n",
    "                elif logL[p1] in oneToMP1D:\n",
    "                    split_rank = self.Get_Rank_Posistion(\n",
    "                        len(mapRelation1DS[logL[p1]]), oneToMP1D[logL[p1]], True\n",
    "                    )\n",
    "                    if split_rank == 1:\n",
    "                        if logL[p1] not in newPartitionsD:\n",
    "                            newPartitionsD[logL[p1]] = Partition(\n",
    "                                stepNo=3, numOfLogs=0, lenOfLogs=partition.lenOfLogs\n",
    "                            )\n",
    "                        newPartitionsD[logL[p1]].logLL.append(logL)\n",
    "                        newPartitionsD[logL[p1]].numOfLogs += 1\n",
    "                    else:\n",
    "                        if logL[p2] not in newPartitionsD:\n",
    "                            newPartitionsD[logL[p2]] = Partition(\n",
    "                                stepNo=3, numOfLogs=0, lenOfLogs=partition.lenOfLogs\n",
    "                            )\n",
    "                        newPartitionsD[logL[p2]].logLL.append(logL)\n",
    "                        newPartitionsD[logL[p2]].numOfLogs += 1\n",
    "\n",
    "                # If is M-1\n",
    "                elif logL[p2] in oneToMP2D:\n",
    "                    split_rank = self.Get_Rank_Posistion(\n",
    "                        len(mapRelation2DS[logL[p2]]), oneToMP2D[logL[p2]], False\n",
    "                    )\n",
    "                    if split_rank == 1:\n",
    "                        if logL[p1] not in newPartitionsD:\n",
    "                            newPartitionsD[logL[p1]] = Partition(\n",
    "                                stepNo=3, numOfLogs=0, lenOfLogs=partition.lenOfLogs\n",
    "                            )\n",
    "                        newPartitionsD[logL[p1]].logLL.append(logL)\n",
    "                        newPartitionsD[logL[p1]].numOfLogs += 1\n",
    "                    else:\n",
    "                        if logL[p2] not in newPartitionsD:\n",
    "                            newPartitionsD[logL[p2]] = Partition(\n",
    "                                stepNo=3, numOfLogs=0, lenOfLogs=partition.lenOfLogs\n",
    "                            )\n",
    "                        newPartitionsD[logL[p2]].logLL.append(logL)\n",
    "                        newPartitionsD[logL[p2]].numOfLogs += 1\n",
    "\n",
    "                # M-M\n",
    "                else:\n",
    "                    if partition.stepNo == 2:\n",
    "                        newPartitionsD[\"dumpKeyforMMrelationInStep2__\"].logLL.append(\n",
    "                            logL\n",
    "                        )\n",
    "                        newPartitionsD[\"dumpKeyforMMrelationInStep2__\"].numOfLogs += 1\n",
    "                    else:\n",
    "                        if len(p1Set) < len(p2Set):\n",
    "                            if logL[p1] not in newPartitionsD:\n",
    "                                newPartitionsD[logL[p1]] = Partition(\n",
    "                                    stepNo=3, numOfLogs=0, lenOfLogs=partition.lenOfLogs\n",
    "                                )\n",
    "                            newPartitionsD[logL[p1]].logLL.append(logL)\n",
    "                            newPartitionsD[logL[p1]].numOfLogs += 1\n",
    "                        else:\n",
    "                            if logL[p2] not in newPartitionsD:\n",
    "                                newPartitionsD[logL[p2]] = Partition(\n",
    "                                    stepNo=3, numOfLogs=0, lenOfLogs=partition.lenOfLogs\n",
    "                                )\n",
    "                            newPartitionsD[logL[p2]].logLL.append(logL)\n",
    "                            newPartitionsD[logL[p2]].numOfLogs += 1\n",
    "\n",
    "            if (\n",
    "                \"dumpKeyforMMrelationInStep2__\" in newPartitionsD\n",
    "                and newPartitionsD[\"dumpKeyforMMrelationInStep2__\"].numOfLogs == 0\n",
    "            ):\n",
    "                newPartitionsD[\"dumpKeyforMMrelationInStep2__\"].valid = False\n",
    "            # Add all the new partitions to collection\n",
    "            for key in newPartitionsD:\n",
    "                if (\n",
    "                    self.params.PST != 0\n",
    "                    and 1.0 * newPartitionsD[key].numOfLogs / partition.numOfLogs\n",
    "                    < self.params.PST\n",
    "                ):\n",
    "                    self.partitionsL[0].logLL += newPartitionsD[key].logLL\n",
    "                    self.partitionsL[0].numOfLogs += newPartitionsD[key].numOfLogs\n",
    "                else:\n",
    "                    self.partitionsL.append(newPartitionsD[key])\n",
    "\n",
    "            partition.valid = False\n",
    "\n",
    "    def step4(self):\n",
    "        self.partitionsL[0].valid = False\n",
    "        if self.params.PST == 0 and self.partitionsL[0].numOfLogs != 0:\n",
    "            event = Event([\"Outlier\"])\n",
    "            event.eventCount = self.partitionsL[0].numOfLogs\n",
    "            self.eventsL.append(event)\n",
    "\n",
    "            for logL in self.partitionsL[0].logLL:\n",
    "                logL.append(str(event.eventId))\n",
    "\n",
    "        for partition in self.partitionsL:\n",
    "            if not partition.valid:\n",
    "                continue\n",
    "\n",
    "            if partition.numOfLogs == 0:\n",
    "                print(str(partition.stepNo) + \"\\t\")\n",
    "\n",
    "            uniqueTokensCountLS = []\n",
    "            for columnIdx in range(partition.lenOfLogs):\n",
    "                uniqueTokensCountLS.append(set())\n",
    "\n",
    "            for logL in partition.logLL:\n",
    "                for columnIdx in range(partition.lenOfLogs):\n",
    "                    uniqueTokensCountLS[columnIdx].add(logL[columnIdx])\n",
    "\n",
    "            e = copy.deepcopy(partition.logLL[0])[: partition.lenOfLogs]\n",
    "\n",
    "            for columnIdx in range(partition.lenOfLogs):\n",
    "                if len(uniqueTokensCountLS[columnIdx]) == 1:\n",
    "                    continue\n",
    "                else:\n",
    "                    e[columnIdx] = \"<*>\"\n",
    "\n",
    "            event = Event(e)\n",
    "            event.eventCount = partition.numOfLogs\n",
    "\n",
    "            self.eventsL.append(event)\n",
    "\n",
    "            for logL in partition.logLL:\n",
    "                logL.append(str(event.eventId))\n",
    "\n",
    "    def get_out_put(self):\n",
    "        output = []\n",
    "        if self.params.PST == 0 and self.partitionsL[0].numOfLogs != 0:\n",
    "            for logL in self.partitionsL[0].logLL:\n",
    "                output.append(logL[-2:] + logL[:-2])\n",
    "        for partition in self.partitionsL:\n",
    "            if not partition.valid:\n",
    "                continue\n",
    "            for logL in partition.logLL:\n",
    "                output.append(logL[-2:] + logL[:-2])\n",
    "        return output\n",
    "\n",
    "    def fit(self, loglines: pd.Series):\n",
    "        self.step1(loglines)\n",
    "        self.step2()\n",
    "        self.step3()\n",
    "        self.step4()\n",
    "\n",
    "\n",
    "    def parse(self, loglines: pd.Series) -> pd.DataFrame:\n",
    "        self.fit(loglines)\n",
    "        return self.get_out_put()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params = IPLoMParams()\n",
    "\n",
    "parser = IPLoM(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"/Users/qcheng/workspace/gitsoma/logai/tests/logai/test_data/default_logrecord_body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loglines = df.logline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/gm/zf03v70n4ndcrg17spcgnrk80000gq/T/ipykernel_44614/2850027884.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mres\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparser\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloglines\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/gm/zf03v70n4ndcrg17spcgnrk80000gq/T/ipykernel_44614/1793382673.py\u001B[0m in \u001B[0;36mparse\u001B[0;34m(self, loglines)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    478\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mparse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloglines\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 479\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloglines\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    480\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_out_put\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    481\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/gm/zf03v70n4ndcrg17spcgnrk80000gq/T/ipykernel_44614/1793382673.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, loglines)\u001B[0m\n\u001B[1;32m    471\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mloglines\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    472\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep1\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mloglines\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 473\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    474\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep3\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    475\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstep4\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/gm/zf03v70n4ndcrg17spcgnrk80000gq/T/ipykernel_44614/1793382673.py\u001B[0m in \u001B[0;36mstep2\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    118\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0mlogL\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpartition\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlogLL\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    119\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0mcolumnIdx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpartition\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlenOfLogs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 120\u001B[0;31m                     \u001B[0muniqueTokensCountLS\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcolumnIdx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlogL\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mcolumnIdx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    121\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    122\u001B[0m             \u001B[0;31m# Find the column with minimum unique tokens\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "res = parser.parse(loglines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(parser.partitionsL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/gm/zf03v70n4ndcrg17spcgnrk80000gq/T/ipykernel_44614/3317084854.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mmatch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mre\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msearch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mr'\\d{4}-\\d{2}-\\d{2}'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlogline\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0mdatetime\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdatetime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mstrptime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmatch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroup\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'%Y-%m-%d'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "# identify timestamp\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "logline = \"20171223-22:15:29:606|Step_LSC|30002312|onStan.\"\n",
    "\n",
    "match = re.search(r'\\d{4}-\\d{2}-\\d{2}', logline)\n",
    "# datetime = datetime.strptime(match.group(), '%Y-%m-%d')\n",
    "\n",
    "\n",
    "# def identify_datetime(str):\n",
    "#     match = re.search(r'\\d{4}-\\d{2}-\\d{2}', text)\n",
    "#     datetime = datetime.strptime(match.group(), '%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Unknown string format: 20171223-22:15:29:606",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mParserError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/gm/zf03v70n4ndcrg17spcgnrk80000gq/T/ipykernel_44614/3343638730.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0ml\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mlogline\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"|\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdparser\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0ml\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfuzzy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/gitsoma/logai/venv/lib/python3.7/site-packages/dateutil/parser/_parser.py\u001B[0m in \u001B[0;36mparse\u001B[0;34m(timestr, parserinfo, **kwargs)\u001B[0m\n\u001B[1;32m   1366\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mparser\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparserinfo\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimestr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1367\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1368\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mDEFAULTPARSER\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimestr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1369\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1370\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/workspace/gitsoma/logai/venv/lib/python3.7/site-packages/dateutil/parser/_parser.py\u001B[0m in \u001B[0;36mparse\u001B[0;34m(self, timestr, default, ignoretz, tzinfos, **kwargs)\u001B[0m\n\u001B[1;32m    641\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    642\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mres\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 643\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mParserError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Unknown string format: %s\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimestr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    644\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    645\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mres\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mParserError\u001B[0m: Unknown string format: 20171223-22:15:29:606"
     ]
    }
   ],
   "source": [
    "import dateutil.parser as dparser\n",
    "\n",
    "for l in logline.split(\"|\"):\n",
    "    print(dparser.parse(l, fuzzy=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}